{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration analysis\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "It will be analysed immigration data alongside temperature, demographic and airport code data. Generating a better quantitative understanding of immigration across the years in the USA.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The project will use Airflow, AWS EMR and Delta to generate bronze, silver and gold layers of data to facilitate the analyses of immigration data in the USA.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Four datasets are going to be used in this project:\n",
    "- I94 Immigration Data: This data comes from the US National Tourism and Trade Office. It has information about immigration along the years;\n",
    "- World Temperature Data: This dataset came from Kaggle. It has information about temperature in cities around the world;\n",
    "- U.S. City Demographic Data: This data comes from OpenSoft. It has information about USA demography;\n",
    "- Airport Code Table: This is a simple table of airport codes and corresponding cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = \"\"\n",
    "secret_key = \"\"\n",
    "with open('credentials.txt') as f:\n",
    "    content = f.read()\n",
    "    access_key = content.split(\",\")[0]\n",
    "    secret_key = content.split(\",\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pyspark --packages io.delta:delta-core_2.12:2.2.0 --conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\" --conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "# !pip install delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install delta-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/29 15:08:55 WARN Utils: Your hostname, BRSAOLN042734 resolves to a loopback address: 127.0.1.1; using 192.168.0.45 instead (on interface wlp0s20f3)\n",
      "23/03/29 15:08:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://repos.spark-packages.org/ added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /home/renan_nunes/.ivy2/cache\n",
      "The jars for the packages stored in: /home/renan_nunes/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-8ea1e4a3-467f-4c16-87d2-50f427cd1f79;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.2.0 in central\n",
      "\tfound io.delta#delta-storage;2.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.563 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/renan_nunes/.virtualenvs/spark-udacity/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":: resolution report :: resolve 147ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.563 from central in [default]\n",
      "\tio.delta#delta-core_2.12;2.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-8ea1e4a3-467f-4c16-87d2-50f427cd1f79\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/4ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/29 15:09:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/29 15:09:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from delta import *\n",
    "import pyspark\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\"). \\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.2.0,org.apache.hadoop:hadoop-aws:3.2.2\").\\\n",
    "    config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\").\\\n",
    "    config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\").\\\n",
    "    config(\"spark.hadoop.fs.s3a.access.key\", access_key).\\\n",
    "    config(\"spark.hadoop.fs.s3a.secret.key\", secret_key).\\\n",
    "    config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider').\\\n",
    "    enableHiveSupport()\n",
    "\n",
    "spark = builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sas_data_df = spark.read.parquet(\"data/sas_data\")\n",
    "sas_data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 3096313; Columns: 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rows: {sas_data_df.count()}; Columns: {len(sas_data_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/29 15:09:22 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5748522.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20579.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.498180e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5748523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20586.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497969e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5748524.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20586.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497975e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5748525.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497325e+10</td>\n",
       "      <td>00028</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5748526.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.501355e+10</td>\n",
       "      <td>00002</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "5  5748522.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "6  5748523.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "7  5748524.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "8  5748525.0  2016.0     4.0   245.0   464.0     HOU  20574.0      1.0   \n",
       "9  5748526.0  2016.0     4.0   245.0   464.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa  \\\n",
       "0      CA  20582.0    40.0      1.0    1.0  20160430      SYD  None       G   \n",
       "1      NV  20591.0    32.0      1.0    1.0  20160430      SYD  None       G   \n",
       "2      WA  20582.0    29.0      1.0    1.0  20160430      SYD  None       G   \n",
       "3      WA  20588.0    29.0      1.0    1.0  20160430      SYD  None       G   \n",
       "4      WA  20588.0    28.0      1.0    1.0  20160430      SYD  None       G   \n",
       "5      HI  20579.0    57.0      2.0    1.0  20160430      ACK  None       G   \n",
       "6      HI  20586.0    66.0      2.0    1.0  20160430      ACK  None       G   \n",
       "7      HI  20586.0    41.0      2.0    1.0  20160430      ACK  None       G   \n",
       "8      FL  20581.0    27.0      2.0    1.0  20160430      ACK  None       G   \n",
       "9      CA  20581.0    26.0      2.0    1.0  20160430      ACK  None       G   \n",
       "\n",
       "  entdepd entdepu matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0       O    None       M   1976.0  10292016      F   None      QF   \n",
       "1       O    None       M   1984.0  10292016      F   None      VA   \n",
       "2       O    None       M   1987.0  10292016      M   None      DL   \n",
       "3       O    None       M   1987.0  10292016      F   None      DL   \n",
       "4       O    None       M   1988.0  10292016      M   None      DL   \n",
       "5       O    None       M   1959.0  10292016      M   None      NZ   \n",
       "6       O    None       M   1950.0  10292016      F   None      NZ   \n",
       "7       O    None       M   1975.0  10292016      F   None      NZ   \n",
       "8       O    None       M   1989.0  10292016      M   None      NZ   \n",
       "9       O    None       M   1990.0  10292016      F   None      NZ   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  9.495387e+10  00011       B1  \n",
       "1  9.495562e+10  00007       B1  \n",
       "2  9.495641e+10  00040       B1  \n",
       "3  9.495645e+10  00040       B1  \n",
       "4  9.495639e+10  00040       B1  \n",
       "5  9.498180e+10  00010       B2  \n",
       "6  9.497969e+10  00010       B2  \n",
       "7  9.497975e+10  00010       B2  \n",
       "8  9.497325e+10  00028       B2  \n",
       "9  9.501355e+10  00002       B2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "sas_data_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way we can see how this dataset looks like. It is also possible to notice that `i94port` seems to be a code, so next dataset to explore will be the \"Airport Code Table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes_df = spark.read.option(\"header\", True).csv('data/airport-codes_csv.csv')\n",
    "airport_codes_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>None</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>3810</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>None</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>-112.16500091552734, 34.305599212646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00CA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldstone /Gts/ Airport</td>\n",
       "      <td>3038</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Barstow</td>\n",
       "      <td>00CA</td>\n",
       "      <td>None</td>\n",
       "      <td>00CA</td>\n",
       "      <td>-116.888000488, 35.350498199499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00CL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Williams Ag Airport</td>\n",
       "      <td>87</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>00CL</td>\n",
       "      <td>None</td>\n",
       "      <td>00CL</td>\n",
       "      <td>-121.763427, 39.427188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00CN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Kitchen Creek Helibase Heliport</td>\n",
       "      <td>3350</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>00CN</td>\n",
       "      <td>None</td>\n",
       "      <td>00CN</td>\n",
       "      <td>-116.4597417, 32.7273736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "5  00AS  small_airport                      Fulton Airport         1100   \n",
       "6  00AZ  small_airport                      Cordes Airport         3810   \n",
       "7  00CA  small_airport             Goldstone /Gts/ Airport         3038   \n",
       "8  00CL  small_airport                 Williams Ag Airport           87   \n",
       "9  00CN       heliport     Kitchen Creek Helibase Heliport         3350   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "5        NA          US      US-OK          Alex     00AS      None   \n",
       "6        NA          US      US-AZ        Cordes     00AZ      None   \n",
       "7        NA          US      US-CA       Barstow     00CA      None   \n",
       "8        NA          US      US-CA         Biggs     00CL      None   \n",
       "9        NA          US      US-CA   Pine Valley     00CN      None   \n",
       "\n",
       "  local_code                              coordinates  \n",
       "0        00A       -74.93360137939453, 40.07080078125  \n",
       "1       00AA                   -101.473911, 38.704022  \n",
       "2       00AK              -151.695999146, 59.94919968  \n",
       "3       00AL    -86.77030181884766, 34.86479949951172  \n",
       "4       None                      -91.254898, 35.6087  \n",
       "5       00AS                  -97.8180194, 34.9428028  \n",
       "6       00AZ  -112.16500091552734, 34.305599212646484  \n",
       "7       00CA       -116.888000488, 35.350498199499995  \n",
       "8       00CL                   -121.763427, 39.427188  \n",
       "9       00CN                 -116.4597417, 32.7273736  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_codes_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "| DNMM|large_airport|Murtala Muhammed ...|         135|       AF|         NG|     NG-LA|       Lagos|    DNMM|      LOS|      null|3.321160078048706...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes_df.filter(\"iata_code='LOS'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"LOS\" airport exists but it is from Nigeria while the immigration data has same data from USA cities on `i94addr` which means that these columns probably doesn't represent the same thing so, on the data modeling, they won't have any relations between the two resulting tables\n",
    "\n",
    "Taking a look at \"U.S. City Demographic Data\" now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_cities_df = spark.read.option(\"header\", True).\\\n",
    "                     option(\"delimiter\", \";\").\\\n",
    "                     csv(\"data/us-cities-demographics.csv\")\n",
    "us_cities_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56229</td>\n",
       "      <td>62432</td>\n",
       "      <td>118661</td>\n",
       "      <td>6634</td>\n",
       "      <td>7517</td>\n",
       "      <td>2.4</td>\n",
       "      <td>IL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avondale</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>29.1</td>\n",
       "      <td>38712</td>\n",
       "      <td>41971</td>\n",
       "      <td>80683</td>\n",
       "      <td>4815</td>\n",
       "      <td>8355</td>\n",
       "      <td>3.18</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>11592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Covina</td>\n",
       "      <td>California</td>\n",
       "      <td>39.8</td>\n",
       "      <td>51629</td>\n",
       "      <td>56860</td>\n",
       "      <td>108489</td>\n",
       "      <td>3800</td>\n",
       "      <td>37038</td>\n",
       "      <td>3.56</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>32716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41762</td>\n",
       "      <td>43270</td>\n",
       "      <td>85032</td>\n",
       "      <td>5783</td>\n",
       "      <td>3269</td>\n",
       "      <td>2.77</td>\n",
       "      <td>MO</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High Point</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>51751</td>\n",
       "      <td>58077</td>\n",
       "      <td>109828</td>\n",
       "      <td>5204</td>\n",
       "      <td>16315</td>\n",
       "      <td>2.65</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>11060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City           State Median Age Male Population  \\\n",
       "0     Silver Spring        Maryland       33.8           40601   \n",
       "1            Quincy   Massachusetts       41.0           44129   \n",
       "2            Hoover         Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga      California       34.5           88127   \n",
       "4            Newark      New Jersey       34.6          138040   \n",
       "5            Peoria        Illinois       33.1           56229   \n",
       "6          Avondale         Arizona       29.1           38712   \n",
       "7       West Covina      California       39.8           51629   \n",
       "8          O'Fallon        Missouri       36.0           41762   \n",
       "9        High Point  North Carolina       35.5           51751   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "5             62432           118661               6634         7517   \n",
       "6             41971            80683               4815         8355   \n",
       "7             56860           108489               3800        37038   \n",
       "8             43270            85032               5783         3269   \n",
       "9             58077           109828               5204        16315   \n",
       "\n",
       "  Average Household Size State Code                               Race  Count  \n",
       "0                    2.6         MD                 Hispanic or Latino  25924  \n",
       "1                   2.39         MA                              White  58723  \n",
       "2                   2.58         AL                              Asian   4759  \n",
       "3                   3.18         CA          Black or African-American  24437  \n",
       "4                   2.73         NJ                              White  76402  \n",
       "5                    2.4         IL  American Indian and Alaska Native   1343  \n",
       "6                   3.18         AZ          Black or African-American  11592  \n",
       "7                   3.56         CA                              Asian  32716  \n",
       "8                   2.77         MO                 Hispanic or Latino   2583  \n",
       "9                   2.65         NC                              Asian  11060  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, Kaggle has some graphs for the temperatura data, so it won't be necessary to redo here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps\n",
    "The main data preparation step needed is to extract the meaning of some immigration data using the `I94_SAS_Labels_Descriptions.SAS` file, besides that, the temperature could use some filtering (for USA cities and for not null values) but, since it is simpler, it will be done directly on the Airflow DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe_from_file(file_path, header_identifier):\n",
    "    with open(file_path) as f:\n",
    "        file_content = f.read()\n",
    "    start_of_values = file_content.index(header_identifier)\n",
    "    end_of_values = file_content.index(\";\", start_of_values)\n",
    "\n",
    "    searched_values = file_content[start_of_values:end_of_values]\n",
    "\n",
    "    values_dataframe = pd.DataFrame(columns = [\"code\", \"value\"])\n",
    "\n",
    "    for index, line in enumerate(searched_values.split(\"\\n\")):\n",
    "        if line.find(\"=\") != -1:\n",
    "            breaked_line = line.split(\"=\")\n",
    "            values_dataframe.loc[index] = {\"code\": breaked_line[0].strip(\" '\"),\n",
    "                                           \"value\": breaked_line[1].strip(\" '\")}\n",
    "\n",
    "    return values_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code                                              value\n",
       "2  582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "3  236                                        AFGHANISTAN\n",
       "4  101                                            ALBANIA\n",
       "5  316                                            ALGERIA\n",
       "6  102                                            ANDORRA"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I94CIT_df = generate_dataframe_from_file(\"data/I94_SAS_Labels_Descriptions.SAS\", \"I94CIT\")\n",
    "I94CIT_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "To have a more flexibility, reduce costs and still keep ACID transactions, it was decided that a medallion architecture (with bronze, silver and gold layers) with Delta Lake will be appropriate. It will be presented the data models for each layer:\n",
    "\n",
    "**- Bronze:**\n",
    "\n",
    "It will be the data as is, so without filters, merges or other operations. The schemas are:\n",
    "\n",
    "| Table               | Columns                                                                                                                                                                                                                                       | Id    | FK                                                 | Description                                                     |\n",
    "|---------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------|----------------------------------------------------|-----------------------------------------------------------------|\n",
    "| i94_immigration     | cicid, i94yr, i94mon, i94cit, i94res, i94port, arrdate, i94mode, i94addr, depdate, i94bir, i94visa, count, dtadfile, visapost, occup, entdepa, entdepd, entdepu, matflag, biryear, dtaddto, gender, insnum, airline, admnum, fltno, visatype | cicid | i94cit, i94res, i94port, i94mode, i94addr, i94visa | Table with immigration data                                     |\n",
    "| i94cit_res          | code, value                                                                                                                                                                                                                                   | code  | -                                                  | Table with codes and corresponding values for i94cit and i94res |\n",
    "| i94port             | code, value                                                                                                                                                                                                                                   | code  | -                                                  | Table with codes and corresponding values for i94port           |\n",
    "| i94mode             | code, value                                                                                                                                                                                                                                   | code  | -                                                  | Table with codes and corresponding values for i94mode           |\n",
    "| i94addr             | code, value                                                                                                                                                                                                                                   | code  | -                                                  | Table with codes and corresponding values for i94addr           |\n",
    "| i94visa             | code, value                                                                                                                                                                                                                                   | code  | -                                                  | Table with codes and corresponding values for i94visa           |\n",
    "| world_temperature   | dt, average_temperature, average_temperature_uncertainty, city, country, latitude, longitude                                                                                                                                                  | -     | -                                                  | Table with temperature data                                     |\n",
    "| us_city_demographic | city, state, median_age, male_population, female_population, total_population, number_of_veterans, foreign_born, average_household_size, state_code, race, count                                                                              | -     | -                                                  | Table with US city demographic data                             |\n",
    "| airport_code_table  | ident, type, name, elevation_ft, continent, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates                                                                                                               | -     | -                                                  | Table with airport code data                                    |\n",
    "\n",
    "**- Silver:**\n",
    "\n",
    "To reduce the amount of tables, some merges and filters will be applied, resulting in better tables for the business to use. The resulting schema is:\n",
    "\n",
    "| Table               | Columns                                                                                                                                                                                                                                       | Id    | Description                                                     |\n",
    "|---------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------|-----------------------------------------------------------------|\n",
    "| i94_immigration             | cicid, i94yr, i94mon, i94cit_value, i94res_value, i94port_value, arrdate, i94mode_value, i94addr_value, depdate, i94bir, i94visa_value, count, dtadfile, visapost, occup, entdepa, entdepd, entdepu, matflag, biryear, dtaddto, gender, insnum, airline, admnum, fltno, visatype | cicid | Table with immigration data         |\n",
    "| world_temperature   | dt, average_temperature, average_temperature_uncertainty, city, country, latitude, longitude                                                                                                                                                  | -     | Table with temperature data                                     |\n",
    "| us_city_demographic | city, state, median_age, male_population, female_population, total_population, number_of_veterans, foreign_born, average_household_size, state_code, race, count                                                                              | -     | Table with US city demographic data                             |\n",
    "| airport_code_table  | ident, type, name, elevation_ft, continent, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates                                                                                                               | -     | Table with airport code data                                    |\n",
    "\n",
    "**- Gold:**\n",
    "\n",
    "The gold layer is a project/object specific database, therefore, in this case, will be a single table aiming to show grouped data for US cities by date alongside the temperature for the period to analyse if it appears to have an impact on it. The schema will be:\n",
    "\n",
    "| Table                    | Columns                                                                                 | Description                                                        |\n",
    "|--------------------------|-----------------------------------------------------------------------------------------|--------------------------------------------------------------------|\n",
    "| grouped_immigration_data | city, state, date, immigration_count, i94mode_value, i94visa_value, average_temperature | Grouped data to analyse the immigration grouped by some criterions |\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "To generate these tables, some steps are needed:\n",
    "- Create the tables on Delta format\n",
    "- Move the data as is from s3 to Delta tables to generate the bronze layer\n",
    "- Merge and filter the bronze layer to generate the silver layer\n",
    "- Perform more operations to generate the gold layer\n",
    "- Verify data quality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/29 15:15:18 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "23/03/29 15:15:18 WARN BasicProfileConfigLoader: Your profile name includes a 'profile ' prefix. This is considered part of the profile name in the Java SDK, so you will need to include this prefix in your profile name when you reference this profile from your Java code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from delta.tables import *\n",
    "\n",
    "# bronze layer\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .addColumn(\"cicid\", \"INT\").addColumn(\"i94yr\", \"INT\") \\\n",
    "    .addColumn(\"i94mon\", \"INT\").addColumn(\"i94cit\", \"INT\") \\\n",
    "    .addColumn(\"i94res\", \"INT\").addColumn(\"i94port\", \"STRING\") \\\n",
    "    .addColumn(\"arrdate\", \"INT\").addColumn(\"i94mode\", \"INT\") \\\n",
    "    .addColumn(\"i94addr\", \"STRING\").addColumn(\"depdate\", \"INT\") \\\n",
    "    .addColumn(\"i94bir\", \"INT\").addColumn(\"i94visa\", \"INT\") \\\n",
    "    .addColumn(\"count\", \"INT\").addColumn(\"dtadfile\", \"STRING\") \\\n",
    "    .addColumn(\"visapost\", \"STRING\").addColumn(\"occup\", \"STRING\") \\\n",
    "    .addColumn(\"entdepa\", \"STRING\").addColumn(\"entdepd\", \"STRING\") \\\n",
    "    .addColumn(\"entdepu\", \"STRING\").addColumn(\"matflag\", \"STRING\") \\\n",
    "    .addColumn(\"biryear\", \"INT\").addColumn(\"dtaddto\", \"STRING\") \\\n",
    "    .addColumn(\"gender\", \"STRING\").addColumn(\"insnum\", \"STRING\") \\\n",
    "    .addColumn(\"airline\", \"STRING\").addColumn(\"admnum\", \"INT\") \\\n",
    "    .addColumn(\"fltno\", \"STRING\").addColumn(\"visatype\", \"STRING\") \\\n",
    "    .location(\"/tmp/test\") \\\n",
    "    .execute()\n",
    "i94_immigration = spark.read.format(\"delta\").load(\"/tmp/test\")\n",
    "i94_immigration.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://bronze-layer-udacity/i94_immigration\")\n",
    "\n",
    "\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .addColumn(\"code\", \"INT\").addColumn(\"value\", \"STRING\") \\\n",
    "    .location(\"/tmp/test\") \\\n",
    "    .execute()\n",
    "i94cit_res = spark.read.format(\"delta\").load(\"/tmp/test\")\n",
    "i94cit_res.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://bronze-layer-udacity/i94cit_res\")\n",
    "\n",
    "\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .addColumn(\"code\", \"STRING\").addColumn(\"value\", \"STRING\") \\\n",
    "    .location(\"/tmp/test\") \\\n",
    "    .execute()\n",
    "i94port = spark.read.format(\"delta\").load(\"/tmp/test\")\n",
    "i94port.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://bronze-layer-udacity/i94port\")\n",
    "\n",
    "\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .addColumn(\"code\", \"INT\").addColumn(\"value\", \"STRING\") \\\n",
    "    .location(\"/tmp/test\") \\\n",
    "    .execute()\n",
    "i94mode = spark.read.format(\"delta\").load(\"/tmp/test\")\n",
    "i94mode.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://bronze-layer-udacity/i94mode\")\n",
    "\n",
    "\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .addColumn(\"code\", \"STRING\").addColumn(\"value\", \"STRING\") \\\n",
    "    .location(\"/tmp/test\") \\\n",
    "    .execute()\n",
    "i94addr = spark.read.format(\"delta\").load(\"/tmp/test\")\n",
    "i94addr.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://bronze-layer-udacity/i94addr\")\n",
    "\n",
    "\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .addColumn(\"code\", \"INT\").addColumn(\"value\", \"STRING\") \\\n",
    "    .location(\"/tmp/test\") \\\n",
    "    .execute()\n",
    "i94visa = spark.read.format(\"delta\").load(\"/tmp/test\")\n",
    "i94visa.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://bronze-layer-udacity/i94visa\")\n",
    "\n",
    "\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .addColumn(\"dt\", \"DATE\", generatedAlwaysAs=\"CAST(dt AS DATE)\") \\\n",
    "    .addColumn(\"average_temperature\", \"FLOAT\").addColumn(\"average_temperature_uncertainty\", \"DOUBLE\") \\\n",
    "    .addColumn(\"city\", \"STRING\").addColumn(\"country\", \"STRING\") \\\n",
    "    .addColumn(\"latitude\", \"DOUBLE\").addColumn(\"longitude\", \"DOUBLE\") \\\n",
    "    .location(\"/tmp/test\") \\\n",
    "    .execute()\n",
    "world_temperature = spark.read.format(\"delta\").load(\"/tmp/test\")\n",
    "world_temperature.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://bronze-layer-udacity/world_temperature\")\n",
    "\n",
    "\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .addColumn(\"city\", \"STRING\").addColumn(\"state\", \"STRING\") \\\n",
    "    .addColumn(\"median_age\", \"FLOAT\").addColumn(\"male_population\", \"INT\") \\\n",
    "    .addColumn(\"female_population\", \"INT\").addColumn(\"total_population\", \"INT\") \\\n",
    "    .addColumn(\"number_of_veterans\", \"INT\").addColumn(\"foreign_born\", \"INT\") \\\n",
    "    .addColumn(\"average_household_size\", \"FLOAT\").addColumn(\"state_code\", \"STRING\") \\\n",
    "    .addColumn(\"race\", \"STRING\").addColumn(\"count\", \"INT\") \\\n",
    "    .location(\"/tmp/test\") \\\n",
    "    .execute()\n",
    "us_city_demographic = spark.read.format(\"delta\").load(\"/tmp/test\")\n",
    "us_city_demographic.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://bronze-layer-udacity/us_city_demographic\")\n",
    "\n",
    "\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .addColumn(\"ident\", \"STRING\").addColumn(\"type\", \"STRING\") \\\n",
    "    .addColumn(\"name\", \"STRING\").addColumn(\"elevation_ft\", \"INT\") \\\n",
    "    .addColumn(\"continent\", \"STRING\").addColumn(\"iso_country\", \"STRING\") \\\n",
    "    .addColumn(\"iso_region\", \"STRING\").addColumn(\"municipality\", \"STRING\") \\\n",
    "    .addColumn(\"gps_code\", \"STRING\").addColumn(\"iata_code\", \"STRING\") \\\n",
    "    .addColumn(\"local_code\", \"STRING\").addColumn(\"coordinates\", \"STRING\") \\\n",
    "    .location(\"/tmp/test\") \\\n",
    "    .execute()\n",
    "airport_code_table = spark.read.format(\"delta\").load(\"/tmp/test\")\n",
    "airport_code_table.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://bronze-layer-udacity/airport_code_table\")\n",
    "\n",
    "\n",
    "# the other tables will be generated by querying these\n",
    "# código para subir o airflow e falar que precisar rodar a dag x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Próximos passos:\n",
    "\n",
    "~~- Arrumar melhor a exploração dos dados~~\n",
    "\n",
    "~~- Fazer a preparação dos dados~~\n",
    "\n",
    "~~- Escrever sobre a modelagem~~\n",
    "\n",
    "~~- Fazer o código para criar as tabelas delta~~\n",
    "\n",
    "~~- Validar se tem requisito de redshift no capstone (não tem)~~\n",
    "\n",
    "~~- Baixar os datasets numa pasta datasets (e organizar a pasta local para subir no git) e rodar as células anteriores lendo do arquivo local~~\n",
    "\n",
    "- Subir estado atual num novo repositório no git\n",
    "\n",
    "- Colocar os dados no s3 num bucket landing\n",
    "\n",
    "- Subir o airflow localmente e colocar credenciais da AWS (colocar no readme como fazer)\n",
    "\n",
    "- Testar EMR operator(?)\n",
    "\n",
    "- Fazer uma task para pegar os dados do s3 e jogar para o redshift/delta lake\n",
    "\n",
    "- Fazer uma task para criar a silver layer\n",
    "\n",
    "- Fazer uma task para criar a gold layer\n",
    "\n",
    "- Fazer uma task para a validação dos dados\n",
    "\n",
    "- Rodar algo para formatar na pep8\n",
    "\n",
    "- Complementar o readme e colocar uma foto com a arquitetura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicar como serão os testes na parte de cima\n",
    "# Mostrar um exemplo de teste aqui, mas especificar que a DAG prefica rodar antes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manter essa parte? ou colocar só da gold layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
